{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User and Item based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #  Module for using operating system dependent functionality\n",
    "import csv # Reading csv files\n",
    "import sys # Module contains functions to allow python to interact with system\n",
    "import re # Reader module\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from collections import defaultdict # default dictionary in surprise library\n",
    "import heapq\n",
    "from surprise import SVD,SVDpp # Singular Value decomposition and Singular Value decomposition ++\n",
    "from surprise.model_selection import cross_validate #cross validation module in surprise lib\n",
    "from operator import itemgetter\n",
    "from surprise import KNNWithMeans # KNN with means Algorithm\n",
    "from surprise import accuracy # Accuracy function\n",
    "from surprise.model_selection import train_test_split # Test and train data split lib from surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Movielens class to fetch data and to define relative functions to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens:\n",
    "\n",
    "    movieID_to_name = {}\n",
    "    name_to_movieID = {}\n",
    "    ratingsPath = 'C:/Users/Imran/Desktop/Thesis coding/New_Coding/ml-latest-small/ratings.csv'\n",
    "    moviesPath = 'C:/Users/Imran/Desktop/Thesis coding/New_Coding/ml-latest-small/movies.csv'\n",
    "    \n",
    "    def loadMovieLensLatestSmall(self):\n",
    "\n",
    "        os.chdir(os.path.dirname(sys.argv[0])) # Look for files relative to the directory we are running from\n",
    "\n",
    "        ratingsDataset = 0\n",
    "        self.movieID_to_name = {}\n",
    "        self.name_to_movieID = {}\n",
    "\n",
    "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "\n",
    "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
    "\n",
    "        with open(self.moviesPath, newline='', encoding='utf-8') as csvfile:\n",
    "                movieReader = csv.reader(csvfile)\n",
    "                next(movieReader)  #Skip header line\n",
    "                for row in movieReader:\n",
    "                    movieID = int(row[0])\n",
    "                    movieName = row[1]\n",
    "                    self.movieID_to_name[movieID] = movieName\n",
    "                    self.name_to_movieID[movieName] = movieID\n",
    "\n",
    "        return ratingsDataset\n",
    "    \n",
    "    # Fetching Movie name based on movie id\n",
    "    def getMovieName(self, movieID):\n",
    "        if movieID in self.movieID_to_name:\n",
    "            return self.movieID_to_name[movieID]\n",
    "        else:\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our dataset from above define Movielens class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MovieLens()\n",
    "data = ml.loadMovieLensLatestSmall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "sim_options = {'name': 'cosine','user_based': True}\n",
    "sim_options_other = {'name': 'pearson','user_based': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating our KNNWithMeans Model and compute the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "model = KNNWithMeans(k=50, sim_options=sim_options)\n",
    "model.fit(trainset)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top N similar users to our test subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "User = '85' # User id defined here\n",
    "k = 10 # Top-10 Neighbours\n",
    "testUserInnerID = trainset.to_inner_uid(User)\n",
    "similarityRow = simsMatrix[testUserInnerID]\n",
    "\n",
    "similarUsers = []\n",
    "for innerID, score in enumerate(similarityRow):\n",
    "    if (innerID != testUserInnerID):\n",
    "        similarUsers.append( (innerID, score) )\n",
    "kNeighbors = heapq.nlargest(k, similarUsers, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the stuff they rated, and add up ratings for each item, weighted by user similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainset.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        candidates[rating[0]] += (rating[1] / 5.0) * userSimilarityScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of stuff the user has already seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched = {}\n",
    "for itemID, rating in trainset.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User based Collaborative filtering results for user: 85\n",
      "\n",
      "Fargo (1996)\n",
      "Shawshank Redemption, The (1994)\n",
      "Silence of the Lambs, The (1991)\n",
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "Godfather, The (1972)\n",
      "Saving Private Ryan (1998)\n",
      "Victor/Victoria (1982)\n",
      "Usual Suspects, The (1995)\n",
      "12 Angry Men (1957)\n",
      "Apartment, The (1960)\n",
      "Being John Malkovich (1999)\n"
     ]
    }
   ],
   "source": [
    "# Get top-rated items from similar users:\n",
    "print(\"\\nUser based Collaborative filtering results for user: {}\\n\".format(User))\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainset.to_raw_iid(itemID)\n",
    "        \n",
    "        print(ml.getMovieName(int(movieID)))\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switching user_based parameter in (sim_options_icf) to (False) to utilize item based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options_icf = {'name': 'cosine','user_based': False}\n",
    "sim_options_icf_other = {'name': 'pearson','user_based': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intiating our KNNBasic Algorithm and fit our model in trainSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "model_icf = KNNWithMeans(sim_options=sim_options_icf)\n",
    "model_icf.fit(trainset)\n",
    "simsMatrix_icf = model_icf.compute_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "User = '85' # define user here\n",
    "k = 10\n",
    "testItemInnerID = trainset.to_inner_uid(Item)\n",
    "\n",
    "# Get the top K items we rated\n",
    "testItemRatings = trainset.ur[testItemInnerID]\n",
    "kNeighbors_icf = heapq.nlargest(k, testItemRatings, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidates Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similar items to stuff we liked (weighted by rating)\n",
    "candidates_icf = defaultdict(float)\n",
    "for itemID_icf, rating_icf in kNeighbors_icf:\n",
    "    similarityRow_icf = simsMatrix_icf[itemID_icf]\n",
    "    for innerID_icf, score_icf in enumerate(similarityRow_icf):\n",
    "        candidates_icf[innerID_icf] += score_icf * (rating_icf / 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Already watched item dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_items = {}\n",
    "for itemID_icf, rating_icf in trainset.ur[testItemInnerID]:\n",
    "    watched_items[itemID_icf] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item based Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item based Collaborative filtering results for user: 85\n",
      "\n",
      "Formula 51 (2001)\n",
      "Kafka (1991)\n",
      "Nine Lives of Fritz the Cat, The (1974)\n",
      "Duck, You Sucker (1971)\n",
      "Dinner Rush (2000)\n",
      "Life and Death of Peter Sellers, The (2004)\n",
      "Down to You (2000)\n",
      "Great Rock 'n' Roll Swindle, The (1980)\n",
      "Big Red One, The (1980)\n",
      "Last Seduction, The (1994)\n",
      "Breakout (1975)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nItem based Collaborative filtering results for user: {}\\n\".format(Item))\n",
    "# Get top-rated items from similar users:\n",
    "pos_icf = 0\n",
    "for itemID_icf, ratingSum_icf in sorted(candidates_icf.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID_icf in watched_items:\n",
    "        movieID = trainset.to_raw_iid(itemID_icf)\n",
    "        print(ml.getMovieName(int(movieID)))\n",
    "        pos_icf += 1\n",
    "        if (pos_icf > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using above defined trainedset\n",
    "trainset = trainset\n",
    "def GetAntiTestSetForUser(testSubject):\n",
    "        fill = trainset.global_mean\n",
    "        anti_testset = []\n",
    "        u = trainset.to_inner_uid(str(testSubject))\n",
    "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
    "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
    "                                 i in trainset.all_items() if\n",
    "                                 i not in user_items]\n",
    "        return anti_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining svd model and fitting training set\n",
    "\n",
    "model_svd = SVD()\n",
    "model_svd.fit(trainset)\n",
    "User = 85 # define user here\n",
    "testset = GetAntiTestSetForUser(User)\n",
    "predictions_svd = model_svd.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix factorization results using SVD for user: 85\n",
      "\n",
      "12 Angry Men (1957)\n",
      "Shawshank Redemption, The (1994)\n",
      "North by Northwest (1959)\n",
      "Cinema Paradiso (Nuovo cinema Paradiso) (1989)\n",
      "Catch Me If You Can (2002)\n",
      "Inglourious Basterds (2009)\n",
      "Departed, The (2006)\n",
      "Matrix, The (1999)\n",
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "Prestige, The (2006)\n"
     ]
    }
   ],
   "source": [
    "recommendations_svd = []\n",
    "print(\"\\nMatrix factorization results using SVD for user: {}\\n\".format(User))\n",
    "for userID, movieID, actualRating, estimatedRating, _ in predictions_svd:\n",
    "    intMovieID = int(movieID)\n",
    "    recommendations_svd.append((intMovieID, estimatedRating))\n",
    "    recommendations_svd.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "for ratings in recommendations_svd[:10]:\n",
    "    print(ml.getMovieName(ratings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8995  0.8907  0.8976  0.8939  0.8994  0.8962  0.0034  \n",
      "MAE (testset)     0.6913  0.6857  0.6917  0.6904  0.6915  0.6901  0.0022  \n",
      "Fit time          6.35    6.68    6.95    6.60    6.79    6.67    0.20    \n",
      "Test time         0.44    0.29    0.28    0.34    0.25    0.32    0.07    \n"
     ]
    }
   ],
   "source": [
    "vali_svd = cross_validate(model_svd,data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD++ Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svdpp = SVDpp()\n",
    "model_svdpp.fit(trainset)\n",
    "testset = GetAntiTestSetForUser(85) # define user here\n",
    "predictions_SVDpp = model_svdpp.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix factorization results using SVDpp for user: 85\n",
      "\n",
      "Wallace & Gromit: A Close Shave (1995) 4.426455962385103\n",
      "Cool Hand Luke (1967) 4.402788205697453\n",
      "Shakespeare in Love (1998) 4.36263566431943\n",
      "Cinema Paradiso (Nuovo cinema Paradiso) (1989) 4.352866880360092\n",
      "Naked Gun: From the Files of Police Squad!, The (1988) 4.348641403590705\n",
      "It Happened One Night (1934) 4.339278189455737\n",
      "Ran (1985) 4.288524649341065\n",
      "Three Colors: White (Trzy kolory: Bialy) (1994) 4.284801543767897\n",
      "Departed, The (2006) 4.281489764215328\n",
      "Amores Perros (Love's a Bitch) (2000) 4.278302449158791\n"
     ]
    }
   ],
   "source": [
    "recommendations_svdpp = []\n",
    "print(\"\\nMatrix factorization results using SVDpp for user: {}\\n\".format(User))\n",
    "for userID, movieID, actualRating, estimatedRating, _ in predictions_SVDpp:\n",
    "    intMovieID = int(movieID)\n",
    "    recommendations_svdpp.append((intMovieID, estimatedRating))\n",
    "    recommendations_svdpp.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "for ratings in recommendations_svdpp[:10]:\n",
    "    print(ml.getMovieName(ratings[0]), ratings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8803  0.8821  0.8896  0.8882  0.8872  0.8855  0.0036  \n",
      "MAE (testset)     0.6745  0.6786  0.6843  0.6834  0.6770  0.6795  0.0037  \n",
      "Fit time          561.21  589.16  607.05  597.94  657.02  602.48  31.30   \n",
      "Test time         9.88    10.87   10.00   10.99   9.77    10.30   0.52    \n"
     ]
    }
   ],
   "source": [
    "vali_svdpp = cross_validate(model_svdpp,data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
